### Pyspark - Data Engineering common tasks showcase

In this project you will find some `pyspark` notebooks performing simple tasks.

In order to execute them, I used the `docker` container that `start.sh` runs. 

However, the project is purely for demonstration purposes and does not contain any of the resources from which the computation was carried out.

I plan to extend It soon, but for now, the project already shows some of the most common task that a Data Engineer carry out on daily basis:

- [Spark libraries installation from Maven, generic ETL and upsertion](https://github.com/CesareIurlaro/pyspark-proof-of-concept/blob/master/notebooks/etl_and_upsertion.ipynb)

- [Efficient deduplication](https://github.com/CesareIurlaro/pyspark-proof-of-concept/blob/master/notebooks/deduplication.ipynb)

- [Efficient word count](https://github.com/CesareIurlaro/pyspark-proof-of-concept/blob/master/notebooks/word_count.ipynb)
